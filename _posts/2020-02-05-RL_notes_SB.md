---
categories: DL
tags: TD
---
## Introduction


Deep learning (DL) seems like perform everywhere, as it should. The universal function approximation theorem suggested so. The trick behind succss of DL lies in the Math. I care about the math. I think, I am more of an application oriented guy, but I care about math. I need to convince myself to apply any DL. This conviced me to keep a note for me to track the maths and underline principles that I think about certain methodologies and implementation.

This blog intends to cover some of the math behind different DL techniques. This blog doesn't cover the full extends of the maths, so any mathematician will be highly disappointed. Sorry for that! As we move forward, this blog covers basic maths that I think plays the crucial role and their role particularly in a very shallow version. I still prefer pen and sketch paper to do math and their interpret. So, there will be lots of image and pdf. Sorry for the crappy hand writings and shallow overview.

<embed src="https://mxahan.github.io/PDF_files/reinforce_note_1_12.pdf" width="100%" height="850px"/>

<embed src="https://mxahan.github.io/PDF_files/rl_part2.pdf" width="100%" height="850px"/>

